** Data Exploration & leading 
import pandas as pd

df=pd.read_csv('Walmart.csv', encoding_errors='ignore')

df.shape

o/p:(10051, 11)
----------------
df.head()

o/p:invoice_id	Branch	City	category	unit_price	quantity	date	time	payment_method	rating	profit_margin
0	1	WALM003	San Antonio	Health and beauty	$74.69	7.0	05/01/19	13:08:00	Ewallet	9.1	0.48
1	2	WALM048	Harlingen	Electronic accessories	$15.28	5.0	08/03/19	10:29:00	Cash	9.6	0.48
2	3	WALM067	Haltom City	Home and lifestyle	$46.33	7.0	03/03/19	13:23:00	Credit card	7.4	0.33
3	4	WALM064	Bedford	Health and beauty	$58.22	8.0	27/01/19	20:33:00	Ewallet	8.4	0.33
4	5	WALM013	Irving	Sports and travel	$86.31	7.0	08/02/19	10:37:00	Ewallet	5.3	0.48

df.describe()

	invoice_id	quantity	rating	profit_margin
count	10051.000000	10020.000000	10051.000000	10051.000000
mean	5025.741220	2.353493	5.825659	0.393791
std	2901.174372	1.602658	1.763991	0.090669
min	1.000000	1.000000	3.000000	0.180000
25%	2513.500000	1.000000	4.000000	0.330000
50%	5026.000000	2.000000	6.000000	0.330000
75%	7538.500000	3.000000	7.000000	0.480000
max	10000.000000	10.000000	10.000000	0.570000

df.info()

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 10051 entries, 0 to 10050
Data columns (total 11 columns):
 #   Column          Non-Null Count  Dtype  
---  ------          --------------  -----  
 0   invoice_id      10051 non-null  int64  
 1   Branch          10051 non-null  object 
 2   City            10051 non-null  object 
 3   category        10051 non-null  object 
 4   unit_price      10020 non-null  object 
 5   quantity        10020 non-null  float64
 6   date            10051 non-null  object 
 7   time            10051 non-null  object 
 8   payment_method  10051 non-null  object 
 9   rating          10051 non-null  float64
 10  profit_margin   10051 non-null  float64
dtypes: float64(3), int64(1), object(7)
memory usage: 863.9+ KB

#duplicates records
df.duplicated().sum()
o/p:np.int64(51)

#To find the null values 
df.isnull().sum()

invoice_id         0
Branch             0
City               0
category           0
unit_price        31
quantity          31
date               0
time               0
payment_method     0
rating             0
profit_margin      0
dtype: int64


#deopping duplicates 
df.drop_duplicates(inplace= True)

df.duplicated().sum()


#dropping null values 
df.dropna(inplace=True)
df.isnull().sum()

invoice_id        0
Branch            0
City              0
category          0
unit_price        0
quantity          0
date              0
time              0
payment_method    0
rating            0
profit_margin     0
dtype: int64


df.shape
(9969, 11)

#chaging data types
df['unit_price']=df['unit_price'].str.replace('$','').astype(float)
df.head()

invoice_id	Branch	City	category	unit_price	quantity	date	time	payment_method	rating	profit_margin
0	1	WALM003	San Antonio	Health and beauty	74.69	7.0	05/01/19	13:08:00	Ewallet	9.1	0.48
1	2	WALM048	Harlingen	Electronic accessories	15.28	5.0	08/03/19	10:29:00	Cash	9.6	0.48
2	3	WALM067	Haltom City	Home and lifestyle	46.33	7.0	03/03/19	13:23:00	Credit card	7.4	0.33
3	4	WALM064	Bedford	Health and beauty	58.22	8.0	27/01/19	20:33:00	Ewallet	8.4	0.33
4	5	WALM013	Irving	Sports and travel	86.31	7.0	08/02/19	10:37:00	Ewallet	5.3	0.48

df['total']=df['unit_price']*df['quantity']

df.head()


df.to_excel("Walmart_cleaned.xlsx", index=False)



df.columns

import pandas as pd

# Load the CSV
df = pd.read_csv("Walmart_cleaned.csv")

# Convert 'date' from DD/MM/YY to YYYY-MM-DD
df['date'] = pd.to_datetime(df['date'], format='%d/%m/%y')

# Save new CSV
df.to_csv("Walmart_cleaned_fixed.csv", index=False)


import pandas as pd

# Read the CSV file
df = pd.read_csv('Walmart.csv2')

# Convert and save as Excel file
df.to_excel('Walmart.xlsx', index=False)

print("Conversion successful: Walmart.xlsx created")


import psycopg2
import pandas as pd

# Load CSV
df = pd.read_csv('Walmart_cleaned_fixed.csv')

# Clean data if needed
df['quantity'] = df['quantity'].fillna(0).astype(int)
df['date'] = pd.to_datetime(df['date'], errors='coerce')


# Connect to RDS PostgreSQL
conn = psycopg2.connect(
    host='database-1.cpqw2wqiot0l.ap-southeast-2.rds.amazonaws.com',
    database='postgres',
    user='postgres',
    password='MyKaggle2024!'
)
cur = conn.cursor()

# Insert rows one by one
for _, row in df.iterrows():
    cur.execute("""
        INSERT INTO cleaned_kaggle_data (invoice_id, branch, city, category, unit_price, quantity, date, time, payment_method, rating, profit_margin, total)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
    """, tuple(row))

conn.commit()
cur.close()
conn.close()

